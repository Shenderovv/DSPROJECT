{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intro to Data Science\n",
    "## Final project\n",
    "## Porto Seguroâ€™s Safe Driver Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "* To do.. Add description of the project\n",
    "* To do.. Add some visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are the following columns in train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'target', 'ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03',\n",
       "       'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin',\n",
       "       'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin',\n",
       "       'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15',\n",
       "       'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01',\n",
       "       'ps_reg_02', 'ps_reg_03', 'ps_car_01_cat', 'ps_car_02_cat',\n",
       "       'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_06_cat',\n",
       "       'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_10_cat',\n",
       "       'ps_car_11_cat', 'ps_car_11', 'ps_car_12', 'ps_car_13', 'ps_car_14',\n",
       "       'ps_car_15', 'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04',\n",
       "       'ps_calc_05', 'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09',\n",
       "       'ps_calc_10', 'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
       "       'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin',\n",
       "       'ps_calc_19_bin', 'ps_calc_20_bin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# split the data\n",
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "y_train = train['target']\n",
    "\n",
    "X_test = test.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We have checked in which columns there are missing values. The most part of the missing values is in categorical features. Only 4 numerical features have missing values. Missing values in numerical features will be dealing by XGBoost algorithm. Missing values in cat features will be considered as the separate category while encoding procedure runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_reg_03', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_05_cat', 'ps_car_07_cat', 'ps_car_09_cat', 'ps_car_11', 'ps_car_12', 'ps_car_14']\n"
     ]
    }
   ],
   "source": [
    "print([column_name for column_name in X_train.columns if -1 in X_train[column_name].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_reg_03', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_05_cat', 'ps_car_07_cat', 'ps_car_09_cat', 'ps_car_11', 'ps_car_14']\n"
     ]
    }
   ],
   "source": [
    "print([column_name for column_name in X_test.columns if -1 in X_test[column_name].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some categorical features have high cardinality. So, the idea is to use target mean for cat features encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def target_mean_encoding(train_feature, test_feature, target):\n",
    "    temp = pd.concat([train_feature, target], axis=1)\n",
    "    temp = temp.groupby(by=train_feature)[target.name].agg(['mean'])\n",
    "    encoded_train_feature = pd.merge(train_feature.to_frame(), temp.reset_index(), how='left')\n",
    "    encoded_train_feature = encoded_train_feature.drop(train_feature.name, axis=1)\n",
    "    encoded_test_feature = pd.merge(test_feature.to_frame(), temp.reset_index(), how='left')\n",
    "    encoded_test_feature = encoded_test_feature.drop(test_feature.name, axis=1)\n",
    "    return (encoded_train_feature.rename(columns={'mean': train_feature.name})[train_feature.name],\n",
    "            encoded_test_feature.rename(columns={'mean': test_feature.name})[test_feature.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "cat_features = [feature for feature in X_train.columns if 'cat' in feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for feature in cat_features:\n",
    "    X_train[feature], X_test[feature] = target_mean_encoding(X_train[feature], X_test[feature], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The evaluation in this competition on Kaggle is performed by using normalized Gini coefficient. We have found that this metric can be calculated using ROC AUC, in particular, as 2 * roc_auc - 1. So, we will use the usual funaction and the roc_auc make evaluation in our CV procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def gini(actual, pred):\n",
    "    matrix = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
    "    matrix = matrix[np.lexsort((matrix[:,2], -1*matrix[:,1]))]\n",
    "    totalLosses = matrix[:,0].sum()\n",
    "    giniSum = matrix[:,0].cumsum().sum() / totalLosses\n",
    " \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will use XGBoost for our classification task. To perform our CV procedure we use StratifiedKFold splitting from sklearn, because we have unbalanced targets in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The internal cv feature of xgboost algorithms showed us that 100 estimators and learning rate 0.1 is OK for this task. So, we continue with tuning max_tree_depth parameter using grid search procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_tree_depth value:  3\n",
      "gini (function):  0.275427958339 \tgini (roc auc):  0.275427959786\n",
      "\n",
      "max_tree_depth value:  4\n",
      "gini (function):  0.27743021761 \tgini (roc auc):  0.277430211582\n",
      "\n",
      "max_tree_depth value:  6\n",
      "gini (function):  0.274512398979 \tgini (roc auc):  0.274512400426\n",
      "\n",
      "max_tree_depth value:  8\n",
      "gini (function):  0.260478704967 \tgini (roc auc):  0.260478696286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_tree_depths = [3, 4, 6, 8]\n",
    "\n",
    "for max_tree_depth in max_tree_depths:\n",
    "    skf = StratifiedKFold()\n",
    "    roc_auc_scores = []\n",
    "    gini_scores = []\n",
    "\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        X_train_cv, X_test_cv = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_cv, y_test_cv = y_train[train_index], y_train[test_index]\n",
    "        xgb = XGBClassifier(max_depth=max_tree_depth, missing=-1)\n",
    "        xgb.fit(X_train_cv, y_train_cv)\n",
    "        preds = xgb.predict_proba(X_test_cv)\n",
    "        gini_scores.append(gini_normalized(y_test_cv, preds[:,1]))\n",
    "        roc_auc_scores.append(2*roc_auc_score(y_test_cv, preds[:,1])-1)\n",
    "\n",
    "    print('max_tree_depth value: ', max_tree_depth)\n",
    "    print('gini (function): ', np.mean(gini_scores), '\\tgini (roc auc): ', np.mean(roc_auc_scores))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "After choosing the optimal max_tree_depth value equals 4, we tune row_sabsampling and col_subsampling parameters also using grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "row_subsamplings = [0.5, 0.75, 1.0]\n",
    "col_subsamplings = [0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "for row_subsampling in row_subsamplings:\n",
    "    for col_subsampling in col_subsamplings:\n",
    "        skf = StratifiedKFold()\n",
    "        roc_auc_scores = []\n",
    "        gini_scores = []\n",
    "\n",
    "        for train_index, test_index in skf.split(X_train, y_train):\n",
    "            X_train_cv, X_test_cv = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "            y_train_cv, y_test_cv = y_train[train_index], y_train[test_index]\n",
    "            xgb = XGBClassifier(max_depth=4, subsample=row_subsampling, colsample_bytree=col_subsampling, missing=-1)\n",
    "            xgb.fit(X_train_cv, y_train_cv)\n",
    "            preds = xgb.predict_proba(X_test_cv)\n",
    "            gini_scores.append(gini_normalized(y_test_cv, preds[:,1]))\n",
    "            roc_auc_scores.append(2*roc_auc_score(y_test_cv, preds[:,1])-1)\n",
    "\n",
    "        print('row_subsampling value: ', row_subsampling, '\\tcol_subsampling value: ', col_subsampling)\n",
    "        print('gini (function): ', np.mean(gini_scores), '\\tgini (roc auc): ', np.mean(roc_auc_scores))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we are ready to train our final model and make predictions for submitting on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(max_depth=4, subsample=0.75, colsample_bytree=0.8, missing=-1)\n",
    "xgb.fit(X_train, y_train)\n",
    "preds = xgb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(np.array([test['id'].values, preds[:,1]]).transpose(), columns=['id', 'target'])\n",
    "result = result.astype({'id':int})\n",
    "result.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The result is 0.276 score on Public LB."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
